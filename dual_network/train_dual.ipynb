{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching UAV and Satellite Images\n",
    "\n",
    "- city = 'atlanta'\n",
    "- number of uav imgs = 2078\n",
    "- number of sat imgs = 2078\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on GPU: True\n",
      "1 GPUs detected\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "\n",
    "# train on GPU?\n",
    "train_on_gpu = cuda.is_available()\n",
    "print(f\"Train on GPU: {train_on_gpu}\")\n",
    "\n",
    "# Number of GPUs\n",
    "if train_on_gpu:\n",
    "    gpu_count = cuda.device_count()\n",
    "    print(f\"{gpu_count} GPUs detected\")\n",
    "    \n",
    "# change according to for hardware\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Pairs for Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Sat Images in atlanta = 2078\n",
      "#UAV Images in atlanta = 2078\n"
     ]
    }
   ],
   "source": [
    "# Image directories\n",
    "import os\n",
    "\n",
    "data_dir = \"train/\"\n",
    "city = 'atlanta'\n",
    "\n",
    "uav_img_dir = data_dir + city + \"/\" + city + \"_uav/uav/\"\n",
    "sat_img_dir = data_dir + city + \"/\" + city + \"_sat/sat300/\"\n",
    "\n",
    "n_uav = len(os.listdir(uav_img_dir))\n",
    "n_sat = len(os.listdir(sat_img_dir))\n",
    "print(f\"#Sat Images in {city} = {n_sat}\")\n",
    "print(f\"#UAV Images in {city} = {n_uav}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all_sat_LLAHTR', 'all_uav_LLAHTR', 'all_uav_xyzHTR', 'match_array_40', 'sat300_image_paths', 'uav_image_paths']\n",
      "[[ True False False ... False False False]\n",
      " [False  True False ... False False False]\n",
      " [False False  True ... False False False]\n",
      " ...\n",
      " [False False False ...  True False False]\n",
      " [False False False ... False  True False]\n",
      " [False False False ... False False  True]]\n",
      "(30512, 30512)\n"
     ]
    }
   ],
   "source": [
    "# load the match array\n",
    "# A symmetric matrix, representing which uav image\n",
    "# matches with which satellite image\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "filename = \"data_labels.h5\"\n",
    "with h5py.File(filename, 'r') as f:\n",
    "    print (list(f.keys()))\n",
    "#     all_sat_LLAHTR = np.asarray(list(f['all_sat_LLAHTR']))\n",
    "#     all_uav_LLAHTR = np.asarray(list(f['all_uav_LLAHTR']))\n",
    "#     all_uav_xyzHTR = np.asarray(list(f['all_uav_xyzHTR']))\n",
    "#     sat_img_path = list(f['sat300_image_paths'])\n",
    "#     uav_img_path = list(f['uav_image_paths'])\n",
    "    match_array = np.asarray(list(f['match_array_40']))\n",
    "print(match_array)\n",
    "print(match_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2078, 2078)\n",
      "[[   0    0]\n",
      " [   0   10]\n",
      " [   0   15]\n",
      " ...\n",
      " [2075 2075]\n",
      " [2076 2076]\n",
      " [2077 2077]]\n"
     ]
    }
   ],
   "source": [
    "# only for this city\n",
    "match_array = match_array[0:2078,0:2078]\n",
    "print(match_array.shape)\n",
    "\n",
    "matching_pairs = np.transpose(np.nonzero(match_array))\n",
    "print(matching_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3896\n"
     ]
    }
   ],
   "source": [
    "print(len(matching_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0  949]\n",
      " [   0 1731]\n",
      " [   0  835]\n",
      " ...\n",
      " [2075 1180]\n",
      " [2076 1431]\n",
      " [2077 2070]]\n"
     ]
    }
   ],
   "source": [
    "# Generate same number of non-matching pairs\n",
    "non_match_pairs = []\n",
    "for i in range(len(match_array)):\n",
    "    match_idx = np.nonzero(match_array[i,:])\n",
    "    match_idx = np.asarray(match_idx)\n",
    "    for j in range(match_idx.size):\n",
    "        rand_idx = np.random.randint(len(match_array))\n",
    "        while(rand_idx in match_idx):\n",
    "            rand_idx = np.random.randint(len(match_array))\n",
    "        non_match_pairs.append(np.array([i, rand_idx]))\n",
    "non_match_pairs = np.asarray(non_match_pairs)\n",
    "print(non_match_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3896\n"
     ]
    }
   ],
   "source": [
    "print(len(non_match_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390 390\n"
     ]
    }
   ],
   "source": [
    "# We choose 780 pairs for validation set\n",
    "choose_idx_match = []\n",
    "choose_idx_nonmt = []\n",
    "n_validby2 = 390\n",
    "# 390 random indices from 0 to 3895\n",
    "while(len(choose_idx_match) < n_validby2):\n",
    "    to_append = np.random.randint(len(matching_pairs))\n",
    "    if to_append not in choose_idx_match:\n",
    "        choose_idx_match.append(to_append)\n",
    "\n",
    "# 390 random indices from 0 to 3895        \n",
    "while(len(choose_idx_nonmt) < n_validby2):\n",
    "    to_append = np.random.randint(len(non_match_pairs))\n",
    "    if to_append not in choose_idx_nonmt:\n",
    "        choose_idx_nonmt.append(to_append)\n",
    "        \n",
    "print(len(choose_idx_match), len(choose_idx_nonmt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_pairs [[ 187  191]\n",
      " [1460 1473]\n",
      " [1994 1994]\n",
      " ...\n",
      " [ 975 1042]\n",
      " [1079  527]\n",
      " [   5  464]]\n",
      "valid_pairs.shape (780, 2)\n",
      "len(valid_labels) 780\n"
     ]
    }
   ],
   "source": [
    "valid_pairs = np.concatenate((matching_pairs[choose_idx_match], non_match_pairs[choose_idx_nonmt]), axis = 0)\n",
    "print('valid_pairs',valid_pairs)\n",
    "print('valid_pairs.shape',valid_pairs.shape)\n",
    "valid_labels = np.concatenate((np.ones(n_validby2),np.zeros(n_validby2)))\n",
    "print('len(valid_labels)', len(valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7012 [[   0    0]\n",
      " [   0   10]\n",
      " [   0   15]\n",
      " ...\n",
      " [2075 1180]\n",
      " [2076 1431]\n",
      " [2077 2070]]\n",
      "7012 [1. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Keep rest of the image pairs in training set\n",
    "mask_match = np.ones(len(matching_pairs), dtype = bool)\n",
    "mask_match[choose_idx_match] = False\n",
    "mask_nonmt = np.ones(len(non_match_pairs), dtype = bool)\n",
    "mask_nonmt[choose_idx_nonmt] = False\n",
    "# print(len(non_match_pairs))\n",
    "train_match_pairs = matching_pairs[mask_match]\n",
    "train_nonmt_pairs = non_match_pairs[mask_nonmt]\n",
    "# print('matching pairs for training \\n', train_match_pairs.shape, train_match_pairs)\n",
    "# print('non-matching pairs for training \\n', train_nonmt_pairs.shape, train_nonmt_pairs)\n",
    "train_pairs = np.concatenate((train_match_pairs, train_nonmt_pairs), axis = 0)\n",
    "print(len(train_pairs), train_pairs)\n",
    "n_trainby2 = len(matching_pairs) - n_validby2\n",
    "train_labels = np.concatenate((np.ones(n_trainby2), np.zeros(n_trainby2)))\n",
    "print(len(train_labels), train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save valid and train pairs\n",
    "import pickle\n",
    "tp_file = 'results/siamese0/train_pair'\n",
    "vp_file = 'results/siamese0/valid_pair'\n",
    "with open(tp_file, 'wb') as f:\n",
    "    pickle.dump(train_pairs, f)\n",
    "with open(vp_file, 'wb') as f:\n",
    "    pickle.dump(valid_pairs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code to load the valid and train pairs\n",
    "\n",
    "# no need to write code for train and valid labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make dataset class and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from skimage import io, transform \n",
    "# skimage transform is required for custom Rescale function\n",
    "\n",
    "class GeoDataset(Dataset):\n",
    "    '''\n",
    "    dataset for uav and satellite images\n",
    "    '''\n",
    "    def __init__(self, uav_dir, sat_dir, img_pair_idx, labels, transform):\n",
    "        # TODO: This needs to be changed when using the entire dataset, or multiple cities \n",
    "        self.uav_dir = uav_dir\n",
    "        self.sat_dir = sat_dir\n",
    "        self.img_pair_idx = img_pair_idx\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.labels.size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        uav_img_name = os.path.join(self.uav_dir, \"uav\" + str(self.img_pair_idx[idx][0]) + \".png\")\n",
    "        sat_img_name = os.path.join(self.sat_dir, \"sat\" + str(self.img_pair_idx[idx][1]) + \".png\")\n",
    "        uav_img = io.imread(uav_img_name)\n",
    "        sat_img = io.imread(sat_img_name)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        sample = {'uav_image': uav_img, 'satellite_image': sat_img, 'label': label}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine Rescale and ToTensor in order to work on pair of images\n",
    "# regular functions in torchvision.transforms will not work\n",
    "\n",
    "class Rescale(object):\n",
    "    \n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        uav_img, sat_img = sample['uav_image'], sample['satellite_image']\n",
    "        label = sample['label']\n",
    "        h, w = uav_img.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "#         print(new_h, new_w)\n",
    "        uav_image = transform.resize(uav_img, (new_h, new_w))\n",
    "#         using shortcut because we know both sizes are the same\n",
    "        sat_image = transform.resize(sat_img, (new_h, new_w))\n",
    "\n",
    "        return {'uav_image': uav_image, 'satellite_image': sat_image, 'label': label}\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        uav_img, sat_img, label = sample['uav_image'], sample['satellite_image'], sample['label']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        uav_img = uav_img.transpose((2, 0, 1)) # note that range is 0-255 not 0-1\n",
    "        sat_img = sat_img.transpose((2, 0, 1))\n",
    "        return {'uav_image': torch.from_numpy(uav_img),\n",
    "                'satellite_image': torch.from_numpy(sat_img),\n",
    "                'label': torch.from_numpy(np.asarray(label))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change the arguments when using the entire dataset, or different cities\n",
    "train_dataset = GeoDataset(uav_img_dir, sat_img_dir, train_pairs, train_labels, \n",
    "                         transform = transforms.Compose([Rescale(256),\n",
    "                                                        ToTensor()\n",
    "                                                        ]))\n",
    "valid_dataset = GeoDataset(uav_img_dir, sat_img_dir, train_pairs, train_labels, \n",
    "                         transform = transforms.Compose([Rescale(256),\n",
    "                                                        ToTensor()\n",
    "                                                        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., dtype=torch.float64)\n",
      "tensor(1., dtype=torch.float64)\n",
      "tensor(1., dtype=torch.float64)\n",
      "tensor(1., dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(4):#(len(mini_dataset)):\n",
    "    sample = train_dataset[i]\n",
    "    print(sample['label'])\n",
    "    ax = plt.subplot(2, 4, 2*i + 1)\n",
    "    # plt.tight_layout()\n",
    "    ax.set_title('UAV #{}'.format(i))\n",
    "    ax.axis('off')\n",
    "    plt.imshow(sample['uav_image'].numpy().transpose((1, 2, 0)))\n",
    "    ax = plt.subplot(2, 4, 2*i + 2)\n",
    "    # plt.tight_layout()\n",
    "    ax.set_title('SAT #{}'.format(i))\n",
    "    ax.axis('off')\n",
    "    plt.imshow(sample['satellite_image'].numpy().transpose((1, 2, 0)))\n",
    "plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders: for training batch by batch as allowed by hardware\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_dataset, batch_size=batch_size, shuffle=True),\n",
    "    'valid': DataLoader(valid_dataset, batch_size=batch_size, shuffle=False),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7012"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloaders['train'].dataset)  # this is the number of examples in the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloaders['train']) # this depends on the batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture\n",
    "\n",
    "Use 2 AlexNets, pretrained on ImageNet data, remove the last classifier layer from both.\n",
    "Take the euclidean distance from both the networks as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "alex_GE = models.alexnet(pretrained = True)\n",
    "alex_GM = models.alexnet(pretrained = True)\n",
    "\n",
    "alex_GE.classifier = nn.Sequential(*[alex_GE.classifier[i] for i in range(5)])\n",
    "alex_GM.classifier = nn.Sequential(*[alex_GM.classifier[i] for i in range(5)])\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.GE = alex_GE\n",
    "        self.GM = alex_GM\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.GE(input1)\n",
    "        output2 = self.GM(input2)\n",
    "        output = torch.norm(output1 - output2, p=2, dim=1)\n",
    "        return output\n",
    "\n",
    "model = SiameseNetwork()\n",
    "if train_on_gpu:\n",
    "    model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "Contrastive loss function with a margin of 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "# optimizer = optim.SGD(model.parameters(), lr=1e-05, weight_decay=5e-05, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0005)\n",
    "model.optimizer = optimizer\n",
    "\n",
    "def loss_contrastive(euclidean_distance, label_batch):\n",
    "    margin = 100\n",
    "    loss = torch.mean( (label_batch) * torch.pow(euclidean_distance, 2) +\n",
    "                    (1-label_batch) * torch.pow(torch.clamp(margin - euclidean_distance, min=0.0), 2))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase=train, Epoch: 0\n",
      "% complete 1.82\n",
      "time:  13.72\n",
      "phase=train, Epoch: 0\n",
      "% complete 41.82\n",
      "time:  254.41\n",
      "phase=train, Epoch: 0\n",
      "% complete 81.82\n",
      "time:  494.78\n",
      "valid_loop 0\n",
      "Epoch: 0 \tTraining Loss: 5864.4720\n",
      "Epoch: 0 \tValidation Loss: 2554.0345\n",
      "Average time per epoch in seconds =  1068.24\n",
      "phase=train, Epoch: 1\n",
      "% complete 1.82\n",
      "time:  10.82\n",
      "phase=train, Epoch: 1\n",
      "% complete 41.82\n",
      "time:  248.96\n",
      "phase=train, Epoch: 1\n",
      "% complete 81.82\n",
      "time:  487.13\n",
      "valid_loop 1\n",
      "Epoch: 1 \tTraining Loss: 2563.0820\n",
      "Epoch: 1 \tValidation Loss: 2588.4724\n",
      "Average time per epoch in seconds =  1064.48\n",
      "phase=train, Epoch: 2\n",
      "% complete 1.82\n",
      "time:  10.82\n",
      "phase=train, Epoch: 2\n",
      "% complete 41.82\n",
      "time:  249.18\n",
      "phase=train, Epoch: 2\n",
      "% complete 81.82\n",
      "time:  487.47\n",
      "valid_loop 2\n",
      "Epoch: 2 \tTraining Loss: 2574.6472\n",
      "Epoch: 2 \tValidation Loss: 2491.9399\n",
      "Average time per epoch in seconds =  1063.06\n",
      "phase=train, Epoch: 3\n",
      "% complete 1.82\n",
      "time:  10.86\n",
      "phase=train, Epoch: 3\n",
      "% complete 41.82\n",
      "time:  249.07\n",
      "phase=train, Epoch: 3\n",
      "% complete 81.82\n",
      "time:  487.12\n",
      "valid_loop 3\n",
      "Epoch: 3 \tTraining Loss: 2457.4543\n",
      "Epoch: 3 \tValidation Loss: 2369.5262\n",
      "Average time per epoch in seconds =  1062.41\n",
      "phase=train, Epoch: 4\n",
      "% complete 1.82\n",
      "time:  10.74\n",
      "phase=train, Epoch: 4\n",
      "% complete 41.82\n",
      "time:  248.6\n",
      "phase=train, Epoch: 4\n",
      "% complete 81.82\n",
      "time:  487.29\n",
      "valid_loop 4\n",
      "Epoch: 4 \tTraining Loss: 2098.3263\n",
      "Epoch: 4 \tValidation Loss: 1838.9933\n",
      "Average time per epoch in seconds =  1062.34\n",
      "phase=train, Epoch: 5\n",
      "% complete 1.82\n",
      "time:  10.86\n",
      "phase=train, Epoch: 5\n",
      "% complete 41.82\n",
      "time:  248.97\n",
      "phase=train, Epoch: 5\n",
      "% complete 81.82\n",
      "time:  487.19\n",
      "valid_loop 5\n",
      "Epoch: 5 \tTraining Loss: 2055.2117\n",
      "Epoch: 5 \tValidation Loss: 1767.2510\n",
      "Average time per epoch in seconds =  1061.87\n",
      "phase=train, Epoch: 6\n",
      "% complete 1.82\n",
      "time:  10.87\n",
      "phase=train, Epoch: 6\n",
      "% complete 41.82\n",
      "time:  248.85\n",
      "phase=train, Epoch: 6\n",
      "% complete 81.82\n",
      "time:  486.95\n",
      "valid_loop 6\n",
      "Epoch: 6 \tTraining Loss: 1885.5467\n",
      "Epoch: 6 \tValidation Loss: 1699.0764\n",
      "Average time per epoch in seconds =  1061.54\n",
      "phase=train, Epoch: 7\n",
      "% complete 1.82\n",
      "time:  10.83\n",
      "phase=train, Epoch: 7\n",
      "% complete 41.82\n",
      "time:  248.75\n",
      "phase=train, Epoch: 7\n",
      "% complete 81.82\n",
      "time:  486.73\n",
      "valid_loop 7\n",
      "Epoch: 7 \tTraining Loss: 1892.8826\n",
      "Epoch: 7 \tValidation Loss: 1920.3833\n",
      "Average time per epoch in seconds =  1061.39\n",
      "phase=train, Epoch: 8\n",
      "% complete 1.82\n",
      "time:  10.83\n",
      "phase=train, Epoch: 8\n",
      "% complete 41.82\n",
      "time:  249.62\n",
      "phase=train, Epoch: 8\n",
      "% complete 81.82\n",
      "time:  488.05\n",
      "valid_loop 8\n",
      "Epoch: 8 \tTraining Loss: 1820.1024\n",
      "Epoch: 8 \tValidation Loss: 1556.0136\n",
      "Average time per epoch in seconds =  1061.35\n",
      "phase=train, Epoch: 9\n",
      "% complete 1.82\n",
      "time:  10.9\n",
      "phase=train, Epoch: 9\n",
      "% complete 41.82\n",
      "time:  248.99\n",
      "phase=train, Epoch: 9\n",
      "% complete 81.82\n",
      "time:  487.24\n",
      "valid_loop 9\n",
      "Epoch: 9 \tTraining Loss: 1887.0037\n",
      "Epoch: 9 \tValidation Loss: 1844.7379\n",
      "Average time per epoch in seconds =  1061.27\n",
      "phase=train, Epoch: 10\n",
      "% complete 1.82\n",
      "time:  10.9\n",
      "phase=train, Epoch: 10\n",
      "% complete 41.82\n",
      "time:  249.79\n",
      "phase=train, Epoch: 10\n",
      "% complete 81.82\n",
      "time:  488.73\n",
      "valid_loop 10\n",
      "Epoch: 10 \tTraining Loss: 1762.4564\n",
      "Epoch: 10 \tValidation Loss: 1569.0519\n",
      "Average time per epoch in seconds =  1061.42\n",
      "phase=train, Epoch: 11\n",
      "% complete 1.82\n",
      "time:  10.84\n",
      "phase=train, Epoch: 11\n",
      "% complete 41.82\n",
      "time:  248.81\n",
      "phase=train, Epoch: 11\n",
      "% complete 81.82\n",
      "time:  486.76\n",
      "valid_loop 11\n",
      "Epoch: 11 \tTraining Loss: 1668.9611\n",
      "Epoch: 11 \tValidation Loss: 1573.1279\n",
      "Average time per epoch in seconds =  1061.26\n",
      "phase=train, Epoch: 12\n",
      "% complete 1.82\n",
      "time:  10.79\n",
      "phase=train, Epoch: 12\n",
      "% complete 41.82\n",
      "time:  248.9\n",
      "phase=train, Epoch: 12\n",
      "% complete 81.82\n",
      "time:  486.6\n",
      "valid_loop 12\n",
      "Epoch: 12 \tTraining Loss: 1696.4984\n",
      "Epoch: 12 \tValidation Loss: 1620.5760\n",
      "Average time per epoch in seconds =  1061.09\n",
      "phase=train, Epoch: 13\n",
      "% complete 1.82\n",
      "time:  10.79\n",
      "phase=train, Epoch: 13\n",
      "% complete 41.82\n",
      "time:  248.94\n",
      "phase=train, Epoch: 13\n",
      "% complete 81.82\n",
      "time:  487.27\n",
      "valid_loop 13\n",
      "Epoch: 13 \tTraining Loss: 1651.3524\n",
      "Epoch: 13 \tValidation Loss: 1515.0448\n",
      "Average time per epoch in seconds =  1060.96\n",
      "phase=train, Epoch: 14\n",
      "% complete 1.82\n",
      "time:  10.82\n",
      "phase=train, Epoch: 14\n",
      "% complete 41.82\n",
      "time:  248.74\n",
      "phase=train, Epoch: 14\n",
      "% complete 81.82\n",
      "time:  486.95\n",
      "valid_loop 14\n",
      "Epoch: 14 \tTraining Loss: 1618.2456\n",
      "Epoch: 14 \tValidation Loss: 1430.3955\n",
      "Average time per epoch in seconds =  1060.83\n",
      "phase=train, Epoch: 15\n",
      "% complete 1.82\n",
      "time:  10.79\n",
      "phase=train, Epoch: 15\n",
      "% complete 41.82\n",
      "time:  248.94\n",
      "phase=train, Epoch: 15\n",
      "% complete 81.82\n",
      "time:  486.99\n",
      "valid_loop 15\n",
      "Epoch: 15 \tTraining Loss: 1690.9176\n",
      "Epoch: 15 \tValidation Loss: 1440.4695\n",
      "Average time per epoch in seconds =  1060.77\n",
      "phase=train, Epoch: 16\n",
      "% complete 1.82\n",
      "time:  10.83\n",
      "phase=train, Epoch: 16\n",
      "% complete 41.82\n",
      "time:  248.98\n",
      "phase=train, Epoch: 16\n",
      "% complete 81.82\n",
      "time:  486.92\n",
      "valid_loop 16\n",
      "Epoch: 16 \tTraining Loss: 1474.6356\n",
      "Epoch: 16 \tValidation Loss: 1307.1500\n",
      "Average time per epoch in seconds =  1060.73\n",
      "phase=train, Epoch: 17\n",
      "% complete 1.82\n",
      "time:  10.8\n",
      "phase=train, Epoch: 17\n",
      "% complete 41.82\n",
      "time:  248.9\n",
      "phase=train, Epoch: 17\n",
      "% complete 81.82\n",
      "time:  486.88\n",
      "valid_loop 17\n",
      "Epoch: 17 \tTraining Loss: 1474.4325\n",
      "Epoch: 17 \tValidation Loss: 1448.7969\n",
      "Average time per epoch in seconds =  1060.67\n",
      "phase=train, Epoch: 18\n",
      "% complete 1.82\n",
      "time:  10.79\n",
      "phase=train, Epoch: 18\n",
      "% complete 41.82\n",
      "time:  250.99\n",
      "phase=train, Epoch: 18\n",
      "% complete 81.82\n",
      "time:  492.22\n",
      "valid_loop 18\n",
      "Epoch: 18 \tTraining Loss: 1411.5128\n",
      "Epoch: 18 \tValidation Loss: 1171.5712\n",
      "Average time per epoch in seconds =  1061.13\n",
      "phase=train, Epoch: 19\n",
      "% complete 1.82\n",
      "time:  10.77\n",
      "phase=train, Epoch: 19\n",
      "% complete 41.82\n",
      "time:  249.02\n",
      "phase=train, Epoch: 19\n",
      "% complete 81.82\n",
      "time:  487.7\n",
      "valid_loop 19\n",
      "Epoch: 19 \tTraining Loss: 1379.3521\n",
      "Epoch: 19 \tValidation Loss: 1114.1356\n",
      "Average time per epoch in seconds =  1061.13\n",
      "phase=train, Epoch: 20\n",
      "% complete 1.82\n",
      "time:  10.78\n",
      "phase=train, Epoch: 20\n",
      "% complete 41.82\n",
      "time:  249.08\n",
      "phase=train, Epoch: 20\n",
      "% complete 81.82\n",
      "time:  487.14\n",
      "valid_loop 20\n",
      "Epoch: 20 \tTraining Loss: 1434.3082\n",
      "Epoch: 20 \tValidation Loss: 1359.0515\n",
      "Average time per epoch in seconds =  1061.25\n",
      "phase=train, Epoch: 21\n",
      "% complete 1.82\n",
      "time:  10.94\n",
      "phase=train, Epoch: 21\n",
      "% complete 41.82\n",
      "time:  252.25\n",
      "phase=train, Epoch: 21\n",
      "% complete 81.82\n",
      "time:  510.66\n",
      "valid_loop 21\n",
      "Epoch: 21 \tTraining Loss: 1391.2770\n",
      "Epoch: 21 \tValidation Loss: 1105.4642\n",
      "Average time per epoch in seconds =  1062.94\n",
      "phase=train, Epoch: 22\n",
      "% complete 1.82\n",
      "time:  10.84\n",
      "phase=train, Epoch: 22\n",
      "% complete 41.82\n",
      "time:  249.49\n",
      "phase=train, Epoch: 22\n",
      "% complete 81.82\n",
      "time:  488.76\n",
      "valid_loop 22\n",
      "Epoch: 22 \tTraining Loss: 1379.4518\n",
      "Epoch: 22 \tValidation Loss: 1066.1014\n",
      "Average time per epoch in seconds =  1063.25\n",
      "phase=train, Epoch: 23\n",
      "% complete 1.82\n",
      "time:  11.08\n",
      "phase=train, Epoch: 23\n",
      "% complete 41.82\n",
      "time:  250.71\n",
      "phase=train, Epoch: 23\n",
      "% complete 81.82\n",
      "time:  491.01\n",
      "valid_loop 23\n",
      "Epoch: 23 \tTraining Loss: 1325.0322\n",
      "Epoch: 23 \tValidation Loss: 990.7201\n",
      "Average time per epoch in seconds =  1063.48\n",
      "phase=train, Epoch: 24\n",
      "% complete 1.82\n",
      "time:  10.9\n",
      "phase=train, Epoch: 24\n",
      "% complete 41.82\n",
      "time:  250.3\n",
      "phase=train, Epoch: 24\n",
      "% complete 81.82\n",
      "time:  489.46\n",
      "valid_loop 24\n",
      "Epoch: 24 \tTraining Loss: 1217.4164\n",
      "Epoch: 24 \tValidation Loss: 963.8271\n",
      "Average time per epoch in seconds =  1063.56\n",
      "phase=train, Epoch: 25\n",
      "% complete 1.82\n",
      "time:  10.88\n",
      "phase=train, Epoch: 25\n",
      "% complete 41.82\n",
      "time:  250.44\n",
      "phase=train, Epoch: 25\n",
      "% complete 81.82\n",
      "time:  490.62\n",
      "valid_loop 25\n",
      "Epoch: 25 \tTraining Loss: 1208.6428\n",
      "Epoch: 25 \tValidation Loss: 910.3711\n",
      "Average time per epoch in seconds =  1063.65\n",
      "phase=train, Epoch: 26\n",
      "% complete 1.82\n",
      "time:  10.86\n",
      "phase=train, Epoch: 26\n",
      "% complete 41.82\n",
      "time:  251.75\n",
      "phase=train, Epoch: 26\n",
      "% complete 81.82\n",
      "time:  489.85\n",
      "valid_loop 26\n",
      "Epoch: 26 \tTraining Loss: 1181.0232\n",
      "Epoch: 26 \tValidation Loss: 892.4572\n",
      "Average time per epoch in seconds =  1063.86\n",
      "phase=train, Epoch: 27\n",
      "% complete 1.82\n",
      "time:  10.83\n",
      "phase=train, Epoch: 27\n",
      "% complete 41.82\n",
      "time:  249.89\n",
      "phase=train, Epoch: 27\n",
      "% complete 81.82\n",
      "time:  491.34\n",
      "valid_loop 27\n",
      "Epoch: 27 \tTraining Loss: 1140.8904\n",
      "Epoch: 27 \tValidation Loss: 876.9844\n",
      "Average time per epoch in seconds =  1064.75\n",
      "phase=train, Epoch: 28\n",
      "% complete 1.82\n",
      "time:  10.83\n",
      "phase=train, Epoch: 28\n",
      "% complete 41.82\n",
      "time:  249.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase=train, Epoch: 28\n",
      "% complete 81.82\n",
      "time:  492.11\n",
      "valid_loop 28\n",
      "Epoch: 28 \tTraining Loss: 1052.2507\n",
      "Epoch: 28 \tValidation Loss: 814.7923\n",
      "Average time per epoch in seconds =  1064.86\n",
      "phase=train, Epoch: 29\n",
      "% complete 1.82\n",
      "time:  10.85\n",
      "phase=train, Epoch: 29\n",
      "% complete 41.82\n",
      "time:  249.62\n",
      "phase=train, Epoch: 29\n",
      "% complete 81.82\n",
      "time:  488.42\n",
      "valid_loop 29\n",
      "Epoch: 29 \tTraining Loss: 1073.0915\n",
      "Epoch: 29 \tValidation Loss: 830.9181\n",
      "Average time per epoch in seconds =  1064.8\n",
      "phase=train, Epoch: 30\n",
      "% complete 1.82\n",
      "time:  10.93\n",
      "phase=train, Epoch: 30\n",
      "% complete 41.82\n",
      "time:  251.26\n",
      "phase=train, Epoch: 30\n",
      "% complete 81.82\n",
      "time:  493.19\n",
      "valid_loop 30\n",
      "Epoch: 30 \tTraining Loss: 1094.7027\n",
      "Epoch: 30 \tValidation Loss: 801.9762\n",
      "Average time per epoch in seconds =  1065.18\n",
      "phase=train, Epoch: 31\n",
      "% complete 1.82\n",
      "time:  11.03\n",
      "phase=train, Epoch: 31\n",
      "% complete 41.82\n",
      "time:  251.24\n",
      "phase=train, Epoch: 31\n",
      "% complete 81.82\n",
      "time:  493.65\n",
      "valid_loop 31\n",
      "Epoch: 31 \tTraining Loss: 1052.9864\n",
      "Epoch: 31 \tValidation Loss: 850.1437\n",
      "Average time per epoch in seconds =  1065.38\n",
      "phase=train, Epoch: 32\n",
      "% complete 1.82\n",
      "time:  10.94\n",
      "phase=train, Epoch: 32\n",
      "% complete 41.82\n",
      "time:  251.85\n",
      "phase=train, Epoch: 32\n",
      "% complete 81.82\n",
      "time:  492.32\n",
      "valid_loop 32\n",
      "Epoch: 32 \tTraining Loss: 1004.1150\n",
      "Epoch: 32 \tValidation Loss: 876.3452\n",
      "Average time per epoch in seconds =  1066.09\n",
      "phase=train, Epoch: 33\n",
      "% complete 1.82\n",
      "time:  11.56\n",
      "phase=train, Epoch: 33\n",
      "% complete 41.82\n",
      "time:  253.62\n",
      "phase=train, Epoch: 33\n",
      "% complete 81.82\n",
      "time:  495.47\n",
      "valid_loop 33\n",
      "Epoch: 33 \tTraining Loss: 987.3005\n",
      "Epoch: 33 \tValidation Loss: 647.8814\n",
      "Average time per epoch in seconds =  1066.31\n",
      "phase=train, Epoch: 34\n",
      "% complete 1.82\n",
      "time:  10.95\n",
      "phase=train, Epoch: 34\n",
      "% complete 41.82\n",
      "time:  253.83\n",
      "phase=train, Epoch: 34\n",
      "% complete 81.82\n",
      "time:  493.31\n",
      "valid_loop 34\n",
      "Epoch: 34 \tTraining Loss: 933.4544\n",
      "Epoch: 34 \tValidation Loss: 1110.0047\n",
      "Average time per epoch in seconds =  1066.42\n",
      "phase=train, Epoch: 35\n",
      "% complete 1.82\n",
      "time:  10.94\n",
      "phase=train, Epoch: 35\n",
      "% complete 41.82\n",
      "time:  250.26\n",
      "phase=train, Epoch: 35\n",
      "% complete 81.82\n",
      "time:  489.53\n",
      "valid_loop 35\n",
      "Epoch: 35 \tTraining Loss: 932.2353\n",
      "Epoch: 35 \tValidation Loss: 661.1197\n",
      "Average time per epoch in seconds =  1066.48\n",
      "phase=train, Epoch: 36\n",
      "% complete 1.82\n",
      "time:  10.9\n",
      "phase=train, Epoch: 36\n",
      "% complete 41.82\n",
      "time:  251.31\n",
      "phase=train, Epoch: 36\n",
      "% complete 81.82\n",
      "time:  493.68\n",
      "valid_loop 36\n",
      "Epoch: 36 \tTraining Loss: 936.8101\n",
      "Epoch: 36 \tValidation Loss: 859.7272\n",
      "Average time per epoch in seconds =  1066.64\n",
      "phase=train, Epoch: 37\n",
      "% complete 1.82\n",
      "time:  10.88\n",
      "phase=train, Epoch: 37\n",
      "% complete 41.82\n",
      "time:  250.27\n",
      "phase=train, Epoch: 37\n",
      "% complete 81.82\n",
      "time:  491.54\n",
      "valid_loop 37\n",
      "Epoch: 37 \tTraining Loss: 920.0518\n",
      "Epoch: 37 \tValidation Loss: 682.4080\n",
      "Average time per epoch in seconds =  1066.77\n",
      "phase=train, Epoch: 38\n",
      "% complete 1.82\n",
      "time:  10.92\n",
      "phase=train, Epoch: 38\n",
      "% complete 41.82\n",
      "time:  253.1\n",
      "phase=train, Epoch: 38\n",
      "% complete 81.82\n",
      "time:  492.67\n",
      "valid_loop 38\n",
      "Epoch: 38 \tTraining Loss: 859.2668\n",
      "Epoch: 38 \tValidation Loss: 798.7168\n",
      "Average time per epoch in seconds =  1067.16\n",
      "phase=train, Epoch: 39\n",
      "% complete 1.82\n",
      "time:  10.93\n",
      "phase=train, Epoch: 39\n",
      "% complete 41.82\n",
      "time:  254.7\n",
      "phase=train, Epoch: 39\n",
      "% complete 81.82\n",
      "time:  496.69\n",
      "valid_loop 39\n",
      "Epoch: 39 \tTraining Loss: 909.9292\n",
      "Epoch: 39 \tValidation Loss: 557.7058\n",
      "Average time per epoch in seconds =  1067.3\n",
      "phase=train, Epoch: 40\n",
      "% complete 1.82\n",
      "time:  10.9\n",
      "phase=train, Epoch: 40\n",
      "% complete 41.82\n",
      "time:  250.34\n",
      "phase=train, Epoch: 40\n",
      "% complete 81.82\n",
      "time:  489.79\n",
      "valid_loop 40\n",
      "Epoch: 40 \tTraining Loss: 789.5238\n",
      "Epoch: 40 \tValidation Loss: 523.7411\n",
      "Average time per epoch in seconds =  1068.09\n",
      "phase=train, Epoch: 41\n",
      "% complete 1.82\n",
      "time:  10.94\n",
      "phase=train, Epoch: 41\n",
      "% complete 41.82\n",
      "time:  251.31\n",
      "phase=train, Epoch: 41\n",
      "% complete 81.82\n",
      "time:  493.73\n",
      "valid_loop 41\n",
      "Epoch: 41 \tTraining Loss: 811.5368\n",
      "Epoch: 41 \tValidation Loss: 648.7082\n",
      "Average time per epoch in seconds =  1068.15\n",
      "phase=train, Epoch: 42\n",
      "% complete 1.82\n",
      "time:  10.94\n",
      "phase=train, Epoch: 42\n",
      "% complete 41.82\n",
      "time:  250.79\n",
      "phase=train, Epoch: 42\n",
      "% complete 81.82\n",
      "time:  491.56\n",
      "valid_loop 42\n",
      "Epoch: 42 \tTraining Loss: 809.0865\n",
      "Epoch: 42 \tValidation Loss: 765.8038\n",
      "Average time per epoch in seconds =  1068.17\n",
      "phase=train, Epoch: 43\n",
      "% complete 1.82\n",
      "time:  10.9\n",
      "phase=train, Epoch: 43\n",
      "% complete 41.82\n",
      "time:  250.42\n",
      "phase=train, Epoch: 43\n",
      "% complete 81.82\n",
      "time:  491.09\n",
      "valid_loop 43\n",
      "Epoch: 43 \tTraining Loss: 769.6921\n",
      "Epoch: 43 \tValidation Loss: 525.8764\n",
      "Average time per epoch in seconds =  1068.39\n",
      "phase=train, Epoch: 44\n",
      "% complete 1.82\n",
      "time:  10.96\n",
      "phase=train, Epoch: 44\n",
      "% complete 41.82\n",
      "time:  253.76\n",
      "phase=train, Epoch: 44\n",
      "% complete 81.82\n",
      "time:  496.05\n",
      "valid_loop 44\n",
      "Epoch: 44 \tTraining Loss: 767.9042\n",
      "Epoch: 44 \tValidation Loss: 472.6831\n",
      "Average time per epoch in seconds =  1068.51\n",
      "phase=train, Epoch: 45\n",
      "% complete 1.82\n",
      "time:  10.93\n",
      "phase=train, Epoch: 45\n",
      "% complete 41.82\n",
      "time:  250.23\n",
      "phase=train, Epoch: 45\n",
      "% complete 81.82\n",
      "time:  489.3\n",
      "valid_loop 45\n",
      "Epoch: 45 \tTraining Loss: 769.3907\n",
      "Epoch: 45 \tValidation Loss: 447.8750\n",
      "Average time per epoch in seconds =  1068.43\n",
      "phase=train, Epoch: 46\n",
      "% complete 1.82\n",
      "time:  10.89\n",
      "phase=train, Epoch: 46\n",
      "% complete 41.82\n",
      "time:  250.22\n",
      "phase=train, Epoch: 46\n",
      "% complete 81.82\n",
      "time:  489.84\n",
      "valid_loop 46\n",
      "Epoch: 46 \tTraining Loss: 677.9949\n",
      "Epoch: 46 \tValidation Loss: 432.8948\n",
      "Average time per epoch in seconds =  1068.38\n",
      "phase=train, Epoch: 47\n",
      "% complete 1.82\n",
      "time:  10.8\n",
      "phase=train, Epoch: 47\n",
      "% complete 41.82\n",
      "time:  250.94\n",
      "phase=train, Epoch: 47\n",
      "% complete 81.82\n",
      "time:  491.27\n",
      "valid_loop 47\n",
      "Epoch: 47 \tTraining Loss: 737.7862\n",
      "Epoch: 47 \tValidation Loss: 448.5037\n",
      "Average time per epoch in seconds =  1068.39\n",
      "phase=train, Epoch: 48\n",
      "% complete 1.82\n",
      "time:  10.8\n",
      "phase=train, Epoch: 48\n",
      "% complete 41.82\n",
      "time:  250.35\n",
      "phase=train, Epoch: 48\n",
      "% complete 81.82\n",
      "time:  489.54\n",
      "valid_loop 48\n",
      "Epoch: 48 \tTraining Loss: 722.4399\n",
      "Epoch: 48 \tValidation Loss: 433.9993\n",
      "Average time per epoch in seconds =  1068.31\n",
      "phase=train, Epoch: 49\n",
      "% complete 1.82\n",
      "time:  10.84\n",
      "phase=train, Epoch: 49\n",
      "% complete 41.82\n",
      "time:  250.29\n",
      "phase=train, Epoch: 49\n",
      "% complete 81.82\n",
      "time:  490.99\n",
      "valid_loop 49\n",
      "Epoch: 49 \tTraining Loss: 692.0705\n",
      "Epoch: 49 \tValidation Loss: 569.2464\n",
      "Average time per epoch in seconds =  1068.31\n",
      "phase=train, Epoch: 50\n",
      "% complete 1.82\n",
      "time:  10.92\n",
      "phase=train, Epoch: 50\n",
      "% complete 41.82\n",
      "time:  249.92\n",
      "phase=train, Epoch: 50\n",
      "% complete 81.82\n",
      "time:  489.18\n",
      "valid_loop 50\n",
      "Epoch: 50 \tTraining Loss: 684.0934\n",
      "Epoch: 50 \tValidation Loss: 418.4226\n",
      "Average time per epoch in seconds =  1068.24\n",
      "phase=train, Epoch: 51\n",
      "% complete 1.82\n",
      "time:  10.87\n",
      "phase=train, Epoch: 51\n",
      "% complete 41.82\n",
      "time:  250.06\n",
      "phase=train, Epoch: 51\n",
      "% complete 81.82\n",
      "time:  489.15\n",
      "valid_loop 51\n",
      "Epoch: 51 \tTraining Loss: 647.6004\n",
      "Epoch: 51 \tValidation Loss: 404.2609\n",
      "Average time per epoch in seconds =  1068.18\n",
      "phase=train, Epoch: 52\n",
      "% complete 1.82\n",
      "time:  10.85\n",
      "phase=train, Epoch: 52\n",
      "% complete 41.82\n",
      "time:  250.17\n",
      "phase=train, Epoch: 52\n",
      "% complete 81.82\n",
      "time:  489.08\n",
      "valid_loop 52\n",
      "Epoch: 52 \tTraining Loss: 643.7004\n",
      "Epoch: 52 \tValidation Loss: 418.7987\n",
      "Average time per epoch in seconds =  1068.14\n",
      "phase=train, Epoch: 53\n",
      "% complete 1.82\n",
      "time:  10.93\n",
      "phase=train, Epoch: 53\n",
      "% complete 41.82\n",
      "time:  252.25\n",
      "phase=train, Epoch: 53\n",
      "% complete 81.82\n",
      "time:  491.85\n",
      "valid_loop 53\n",
      "Epoch: 53 \tTraining Loss: 684.0340\n",
      "Epoch: 53 \tValidation Loss: 421.2505\n",
      "Average time per epoch in seconds =  1068.23\n",
      "phase=train, Epoch: 54\n",
      "% complete 1.82\n",
      "time:  10.93\n",
      "phase=train, Epoch: 54\n",
      "% complete 41.82\n",
      "time:  250.2\n",
      "phase=train, Epoch: 54\n",
      "% complete 81.82\n",
      "time:  494.54\n",
      "valid_loop 54\n",
      "Epoch: 54 \tTraining Loss: 640.5050\n",
      "Epoch: 54 \tValidation Loss: 389.1406\n",
      "Average time per epoch in seconds =  1068.33\n",
      "phase=train, Epoch: 55\n",
      "% complete 1.82\n",
      "time:  10.92\n",
      "phase=train, Epoch: 55\n",
      "% complete 41.82\n",
      "time:  249.98\n",
      "phase=train, Epoch: 55\n",
      "% complete 81.82\n",
      "time:  489.49\n",
      "valid_loop 55\n",
      "Epoch: 55 \tTraining Loss: 639.0469\n",
      "Epoch: 55 \tValidation Loss: 425.3286\n",
      "Average time per epoch in seconds =  1068.3\n",
      "phase=train, Epoch: 56\n",
      "% complete 1.82\n",
      "time:  10.85\n",
      "phase=train, Epoch: 56\n",
      "% complete 41.82\n",
      "time:  251.95\n",
      "phase=train, Epoch: 56\n",
      "% complete 81.82\n",
      "time:  493.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loop 56\n",
      "Epoch: 56 \tTraining Loss: 611.4226\n",
      "Epoch: 56 \tValidation Loss: 346.4925\n",
      "Average time per epoch in seconds =  1068.4\n",
      "phase=train, Epoch: 57\n",
      "% complete 1.82\n",
      "time:  10.84\n",
      "phase=train, Epoch: 57\n",
      "% complete 41.82\n",
      "time:  250.5\n",
      "phase=train, Epoch: 57\n",
      "% complete 81.82\n",
      "time:  489.7\n",
      "valid_loop 57\n",
      "Epoch: 57 \tTraining Loss: 590.7284\n",
      "Epoch: 57 \tValidation Loss: 340.9157\n",
      "Average time per epoch in seconds =  1068.34\n",
      "phase=train, Epoch: 58\n",
      "% complete 1.82\n",
      "time:  10.91\n",
      "phase=train, Epoch: 58\n",
      "% complete 41.82\n",
      "time:  250.51\n",
      "phase=train, Epoch: 58\n",
      "% complete 81.82\n",
      "time:  489.4\n",
      "valid_loop 58\n",
      "Epoch: 58 \tTraining Loss: 570.8478\n",
      "Epoch: 58 \tValidation Loss: 424.6640\n",
      "Average time per epoch in seconds =  1068.37\n",
      "phase=train, Epoch: 59\n",
      "% complete 1.82\n",
      "time:  10.87\n",
      "phase=train, Epoch: 59\n",
      "% complete 41.82\n",
      "time:  250.58\n",
      "phase=train, Epoch: 59\n",
      "% complete 81.82\n",
      "time:  489.8\n",
      "valid_loop 59\n",
      "Epoch: 59 \tTraining Loss: 586.4990\n",
      "Epoch: 59 \tValidation Loss: 332.8245\n",
      "Average time per epoch in seconds =  1068.31\n",
      "phase=train, Epoch: 60\n",
      "% complete 1.82\n",
      "time:  10.85\n",
      "phase=train, Epoch: 60\n",
      "% complete 41.82\n",
      "time:  252.04\n",
      "phase=train, Epoch: 60\n",
      "% complete 81.82\n",
      "time:  492.19\n",
      "valid_loop 60\n",
      "Epoch: 60 \tTraining Loss: 576.5757\n",
      "Epoch: 60 \tValidation Loss: 350.2698\n",
      "Average time per epoch in seconds =  1068.61\n",
      "phase=train, Epoch: 61\n",
      "% complete 1.82\n",
      "time:  10.96\n",
      "phase=train, Epoch: 61\n",
      "% complete 41.82\n",
      "time:  251.0\n",
      "phase=train, Epoch: 61\n",
      "% complete 81.82\n",
      "time:  492.96\n",
      "valid_loop 61\n",
      "Epoch: 61 \tTraining Loss: 549.0866\n",
      "Epoch: 61 \tValidation Loss: 338.8072\n",
      "Average time per epoch in seconds =  1068.67\n",
      "phase=train, Epoch: 62\n",
      "% complete 1.82\n",
      "time:  10.92\n",
      "phase=train, Epoch: 62\n",
      "% complete 41.82\n",
      "time:  250.89\n",
      "phase=train, Epoch: 62\n",
      "% complete 81.82\n",
      "time:  490.26\n",
      "valid_loop 62\n",
      "Epoch: 62 \tTraining Loss: 554.6300\n",
      "Epoch: 62 \tValidation Loss: 324.2228\n",
      "Average time per epoch in seconds =  1069.24\n",
      "phase=train, Epoch: 63\n",
      "% complete 1.82\n",
      "time:  10.87\n",
      "phase=train, Epoch: 63\n",
      "% complete 41.82\n",
      "time:  253.9\n",
      "phase=train, Epoch: 63\n",
      "% complete 81.82\n",
      "time:  495.38\n",
      "valid_loop 63\n",
      "Epoch: 63 \tTraining Loss: 536.9828\n",
      "Epoch: 63 \tValidation Loss: 337.7214\n",
      "Average time per epoch in seconds =  1069.34\n",
      "phase=train, Epoch: 64\n",
      "% complete 1.82\n",
      "time:  10.88\n",
      "phase=train, Epoch: 64\n",
      "% complete 41.82\n",
      "time:  250.68\n",
      "phase=train, Epoch: 64\n",
      "% complete 81.82\n",
      "time:  491.78\n",
      "valid_loop 64\n",
      "Epoch: 64 \tTraining Loss: 552.5169\n",
      "Epoch: 64 \tValidation Loss: 391.7116\n",
      "Average time per epoch in seconds =  1069.39\n",
      "phase=train, Epoch: 65\n",
      "% complete 1.82\n",
      "time:  10.87\n",
      "phase=train, Epoch: 65\n",
      "% complete 41.82\n",
      "time:  250.36\n",
      "phase=train, Epoch: 65\n",
      "% complete 81.82\n",
      "time:  491.27\n",
      "valid_loop 65\n",
      "Epoch: 65 \tTraining Loss: 546.2844\n",
      "Epoch: 65 \tValidation Loss: 305.6968\n",
      "Average time per epoch in seconds =  1069.44\n",
      "phase=train, Epoch: 66\n",
      "% complete 1.82\n",
      "time:  10.88\n",
      "phase=train, Epoch: 66\n",
      "% complete 41.82\n",
      "time:  250.34\n",
      "phase=train, Epoch: 66\n",
      "% complete 81.82\n",
      "time:  491.58\n",
      "valid_loop 66\n",
      "Epoch: 66 \tTraining Loss: 560.3571\n",
      "Epoch: 66 \tValidation Loss: 342.6717\n",
      "Average time per epoch in seconds =  1069.46\n",
      "phase=train, Epoch: 67\n",
      "% complete 1.82\n",
      "time:  10.98\n",
      "phase=train, Epoch: 67\n",
      "% complete 41.82\n",
      "time:  252.46\n",
      "phase=train, Epoch: 67\n",
      "% complete 81.82\n",
      "time:  493.07\n",
      "valid_loop 67\n",
      "Epoch: 67 \tTraining Loss: 520.4993\n",
      "Epoch: 67 \tValidation Loss: 345.7639\n",
      "Average time per epoch in seconds =  1069.5\n",
      "phase=train, Epoch: 68\n",
      "% complete 1.82\n",
      "time:  10.82\n",
      "phase=train, Epoch: 68\n",
      "% complete 41.82\n",
      "time:  251.89\n",
      "phase=train, Epoch: 68\n",
      "% complete 81.82\n",
      "time:  497.67\n",
      "valid_loop 68\n",
      "Epoch: 68 \tTraining Loss: 509.6072\n",
      "Epoch: 68 \tValidation Loss: 298.0421\n",
      "Average time per epoch in seconds =  1069.6\n",
      "phase=train, Epoch: 69\n",
      "% complete 1.82\n",
      "time:  10.87\n",
      "phase=train, Epoch: 69\n",
      "% complete 41.82\n",
      "time:  251.02\n",
      "phase=train, Epoch: 69\n",
      "% complete 81.82\n",
      "time:  490.89\n",
      "valid_loop 69\n",
      "Epoch: 69 \tTraining Loss: 537.0960\n",
      "Epoch: 69 \tValidation Loss: 304.5530\n",
      "Average time per epoch in seconds =  1069.61\n",
      "phase=train, Epoch: 70\n",
      "% complete 1.82\n",
      "time:  10.9\n",
      "phase=train, Epoch: 70\n",
      "% complete 41.82\n",
      "time:  251.51\n",
      "phase=train, Epoch: 70\n",
      "% complete 81.82\n",
      "time:  491.43\n",
      "valid_loop 70\n",
      "Epoch: 70 \tTraining Loss: 515.7753\n",
      "Epoch: 70 \tValidation Loss: 326.0036\n",
      "Average time per epoch in seconds =  1069.67\n",
      "phase=train, Epoch: 71\n",
      "% complete 1.82\n",
      "time:  10.85\n",
      "phase=train, Epoch: 71\n",
      "% complete 41.82\n",
      "time:  259.11\n",
      "phase=train, Epoch: 71\n",
      "% complete 81.82\n",
      "time:  504.21\n",
      "valid_loop 71\n",
      "Epoch: 71 \tTraining Loss: 511.5733\n",
      "Epoch: 71 \tValidation Loss: 301.7858\n",
      "Average time per epoch in seconds =  1069.86\n",
      "phase=train, Epoch: 72\n",
      "% complete 1.82\n",
      "time:  10.85\n",
      "phase=train, Epoch: 72\n",
      "% complete 41.82\n",
      "time:  249.41\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-be5e6b925fae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#         TODO: CORRECT THE NON GPU PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain_on_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-a505e991897a>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'uav_image'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muav_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'satellite_image'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msat_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-a2d0276b3f6b>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0muav_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muav_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#         using shortcut because we know both sizes are the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0msat_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msat_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'uav_image'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muav_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'satellite_image'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msat_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         image = ndi.gaussian_filter(image, anti_aliasing_sigma,\n\u001b[0;32m--> 149\u001b[0;31m                                     cval=cval, mode=ndi_mode)\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;31m# 2-dimensional interpolation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/scipy/ndimage/filters.py\u001b[0m in \u001b[0;36mgaussian_filter\u001b[0;34m(input, sigma, order, output, mode, cval, truncate)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             gaussian_filter1d(input, sigma, axis, order, output,\n\u001b[0;32m--> 299\u001b[0;31m                               mode, cval, truncate)\n\u001b[0m\u001b[1;32m    300\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/scipy/ndimage/filters.py\u001b[0m in \u001b[0;36mgaussian_filter1d\u001b[0;34m(input, sigma, axis, order, output, mode, cval, truncate)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;31m# Since we are calling correlate, not convolve, revert the kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gaussian_kernel1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorrelate1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/scipy/ndimage/filters.py\u001b[0m in \u001b[0;36mcorrelate1d\u001b[0;34m(input, weights, axis, output, mode, cval, origin)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ni_support\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_mode_to_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     _nd_image.correlate1d(input, weights, axis, output, mode, cval,\n\u001b[0;32m---> 95\u001b[0;31m                           origin)\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training\n",
    "from timeit import default_timer as timer\n",
    "history = []\n",
    "n_epochs = 150\n",
    "model.epochs = 0\n",
    "print_every = 22 # 110 batches will go in, print 5 times (in 1 epoch)\n",
    "time0 = timer()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    # set to train mode\n",
    "    model.train()\n",
    "    start = timer()\n",
    "    \n",
    "    for ii, sample in enumerate(dataloaders['train']):\n",
    "#         TODO: CORRECT THE NON GPU PART\n",
    "        if train_on_gpu:\n",
    "            uav_img = sample['uav_image'].cuda()\n",
    "            sat_img = sample['satellite_image'].cuda()\n",
    "            label = sample['label'].cuda()\n",
    "        uav_img = uav_img.float()\n",
    "        sat_img = sat_img.float()\n",
    "        label = label.float()\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Predicted outputs are log probabilities\n",
    "        output = model(uav_img, sat_img)\n",
    "        \n",
    "        # Loss and backpropagation of gradients\n",
    "        loss = loss_contrastive(output, label)\n",
    "        loss.backward()\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "#         print('loss.item()',loss.item()) #average loss for the batch_size\n",
    "        # Track train loss by multiplying average loss by number of examples in batch\n",
    "        train_loss += loss.item() * uav_img.size(0) # total loss in 1 epoch = sum of losses in all batch\n",
    "        \n",
    "        if (ii % print_every) == 0 :\n",
    "#             print(uav_img.size(0)) this is basically the batch size\n",
    "            print(f'phase=train, Epoch: {epoch}')\n",
    "            print('% complete',round((100 * (ii + 1) / len(dataloaders['train'])),2)) \n",
    "            print('time: ',round(timer() - start,2))\n",
    "        \n",
    "    model.epochs += 1\n",
    "    \n",
    "    # Don't need to keep track of gradients\n",
    "    with torch.no_grad():\n",
    "        # Set to evaluation mode\n",
    "        model.eval()\n",
    "        print('valid_loop', epoch)\n",
    "        # Validation loop\n",
    "        for ii, sample in enumerate(dataloaders['valid']):\n",
    "            \n",
    "            if train_on_gpu:\n",
    "                uav_img = sample['uav_image'].cuda()\n",
    "                sat_img = sample['satellite_image'].cuda()\n",
    "                label = sample['label'].cuda()\n",
    "            uav_img = uav_img.float()\n",
    "            sat_img = sat_img.float()\n",
    "            label = label.float()\n",
    "            output = model(uav_img, sat_img)\n",
    "            # Loss and backpropagation of gradients\n",
    "            loss = loss_contrastive(output, label)\n",
    "            valid_loss += loss.item() * uav_img.size(0)\n",
    "            \n",
    "    # Calculate average losses\n",
    "    train_loss = train_loss / len(dataloaders['train'].dataset) #total loss / number of img pairs in the dataset\n",
    "    valid_loss = valid_loss / len(dataloaders['valid'].dataset)\n",
    "                \n",
    "    history.append([train_loss, valid_loss])\n",
    "    print(f'Epoch: {epoch} \\tTraining Loss: {train_loss:.4f}')\n",
    "    print(f'Epoch: {epoch} \\tValidation Loss: {valid_loss:.4f}')\n",
    "    print('Average time per epoch in seconds = ', round((timer() - time0)/(epoch+1), 2))\n",
    "print('Total time for training in min = ', round((timer() - time0)/60,2))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_minutes = round((timer() - time0)/60, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1291.41\n"
     ]
    }
   ],
   "source": [
    "print(training_minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5864.471988310218, 2554.034488031678],\n",
       " [2563.082045177018, 2588.4724202566804],\n",
       " [2574.647179054656, 2491.939918983751],\n",
       " [2457.454252809915, 2369.5261637137673],\n",
       " [2098.326333149868, 1838.993335225551],\n",
       " [2055.211694642332, 1767.2510250285225],\n",
       " [1885.546678907587, 1699.0764378810431],\n",
       " [1892.882602341299, 1920.383260392898],\n",
       " [1820.1024138586085, 1556.0136310688374],\n",
       " [1887.003687038737, 1844.7379497869724],\n",
       " [1762.4563780728572, 1569.0519195051786],\n",
       " [1668.9610601273932, 1573.1278782968036],\n",
       " [1696.4983883654807, 1620.5760477852698],\n",
       " [1651.3524339831495, 1515.04477863562],\n",
       " [1618.2456292839506, 1430.3955383126693],\n",
       " [1690.9175774704302, 1440.4695447452805],\n",
       " [1474.6355804251864, 1307.1499765747558],\n",
       " [1474.4325332772166, 1448.7968628834944],\n",
       " [1411.512828733332, 1171.5712227002593],\n",
       " [1379.352112826115, 1114.1355836284004],\n",
       " [1434.3082393770278, 1359.051456222926],\n",
       " [1391.2769561610899, 1105.464177829636],\n",
       " [1379.4517809034958, 1066.1014077011953],\n",
       " [1325.0322461995954, 990.7200604627558],\n",
       " [1217.4163891476219, 963.8270719781714],\n",
       " [1208.6428301343901, 910.371076689403],\n",
       " [1181.023156940223, 892.4571907143558],\n",
       " [1140.8903899815718, 876.9844337023808],\n",
       " [1052.2507119491586, 814.7923106984009],\n",
       " [1073.091460467881, 830.9181087513481],\n",
       " [1094.7027347649564, 801.9761617152404],\n",
       " [1052.9863795853314, 850.1437155445575],\n",
       " [1004.115035984629, 876.3451639056818],\n",
       " [987.3004694937027, 647.8813848065704],\n",
       " [933.4543617191956, 1110.0046947977573],\n",
       " [932.2352880901157, 661.1197181436177],\n",
       " [936.8100584196623, 859.7271887979981],\n",
       " [920.0517522765103, 682.4079518815959],\n",
       " [859.2667870007442, 798.7167775164451],\n",
       " [909.929153468496, 557.7057862442286],\n",
       " [789.5238065659762, 523.7411284547361],\n",
       " [811.5368377981496, 648.7081683910172],\n",
       " [809.0864556547035, 765.8037650787824],\n",
       " [769.6920855054839, 525.876440819644],\n",
       " [767.9041783560771, 472.68314723239513],\n",
       " [769.3906772611349, 447.8750415547399],\n",
       " [677.9949346739295, 432.89475986199994],\n",
       " [737.7861853173578, 448.5037063102483],\n",
       " [722.4399254598144, 433.99928947836077],\n",
       " [692.0704521879902, 569.2463623673591],\n",
       " [684.0933719510972, 418.4226418216094],\n",
       " [647.6003966693258, 404.2609088939051],\n",
       " [643.7004265009983, 418.7986544202684],\n",
       " [684.0340438294397, 421.25052078342816],\n",
       " [640.5049531439407, 389.1406046839625],\n",
       " [639.0468934532988, 425.3286377928016],\n",
       " [611.4225536287681, 346.4924940336655],\n",
       " [590.7283592245882, 340.9157281191228],\n",
       " [570.8477571860627, 424.66396971124277],\n",
       " [586.4989582590559, 332.8245088323755],\n",
       " [576.5757397892675, 350.2697698633397],\n",
       " [549.08660206248, 338.8071694860986],\n",
       " [554.6299829999855, 324.22277652720896],\n",
       " [536.9828397203567, 337.7213764615013],\n",
       " [552.5169375518085, 391.711597623243],\n",
       " [546.2843688686304, 305.6967772915237],\n",
       " [560.3570910386882, 342.67171205388973],\n",
       " [520.4993353504761, 345.7638537705591],\n",
       " [509.6071989730774, 298.04206972617254],\n",
       " [537.0960327775153, 304.5530158226244],\n",
       " [515.7753089430396, 326.00358765205516],\n",
       " [511.5733173585795, 301.7858251907862]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_history = []\n",
    "valid_history = []\n",
    "for ii, i in enumerate(history):\n",
    "#     if ii<=1:\n",
    "#         continue\n",
    "    train_history.append(i[0])\n",
    "    valid_history.append(i[1])\n",
    "plt.plot(range(len(train_history)), train_history, 'b-', label='train loss')\n",
    "plt.plot(range(len(valid_history)), valid_history, 'g-', label='valid loss')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model saving stuff here\n",
    "def save_checkpoint(model, path):\n",
    "    checkpoint = {'epochs': model.epochs}\n",
    "    checkpoint['state_dict'] = model.state_dict()\n",
    "    # Add the optimizer\n",
    "    checkpoint['optimizer'] = model.optimizer\n",
    "    checkpoint['optimizer_state_dict'] = model.optimizer.state_dict()\n",
    "    # train loss\n",
    "    checkpoint['train_loss'] = train_history\n",
    "    checkpoint['valid_loss'] = valid_history\n",
    "    checkpoint['training_minutes'] = training_minutes\n",
    "    torch.save(checkpoint, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"results/siamese0/atlanta_sia_alex.pth\"\n",
    "save_checkpoint(model, checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "import torch\n",
    "\n",
    "def load_checkpoint(path):\n",
    "    model = SiameseNetwork()\n",
    "    if train_on_gpu:\n",
    "        model = model.to('cuda')\n",
    "    \n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    if train_on_gpu:\n",
    "        model = model.to('cuda')\n",
    "    model.epochs = checkpoint['epochs']\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = checkpoint['optimizer']\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go and run everything except the training and saving cell\n",
    "PATH = \"results/siamese0/atlanta_sia_alex.pth\"\n",
    "model, optimizer = load_checkpoint(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Check\n",
    "Draw distance histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3506\n",
      "3506\n"
     ]
    }
   ],
   "source": [
    "# make histograms for matching and non-matching pairs\n",
    "train_match_hist = []\n",
    "train_nonma_hist = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for ii, sample in enumerate(dataloaders['train']):\n",
    "        if train_on_gpu:\n",
    "            uav_img = sample['uav_image'].cuda()\n",
    "            sat_img = sample['satellite_image'].cuda()\n",
    "            label = sample['label'].cuda()\n",
    "        uav_img = uav_img.float()\n",
    "        sat_img = sat_img.float()\n",
    "        label = label.float()\n",
    "        output = model(uav_img, sat_img)\n",
    "        out = output.cpu().detach().numpy()\n",
    "\n",
    "        for i in range(len(output)):\n",
    "            if (label[i]):\n",
    "                train_match_hist.append(out[i])\n",
    "            else:\n",
    "                train_nonma_hist.append(out[i])\n",
    "            \n",
    "print(len(train_match_hist))\n",
    "print(len(train_nonma_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,  90., 121., 114., 112.,  96., 104., 108., 118., 110., 120.,\n",
       "        103.,  88.,  95.,  96., 119., 102.,  76., 111.,  89.,  81.,  93.,\n",
       "         85.,  89.,  82.,  55.,  66.,  59.,  64.,  47.,  63.,  56.,  56.,\n",
       "         50.,  35.,  42.,  35.,  39.,  41.,  38.,  35.,  28.,  32.,  19.,\n",
       "         33.,  26.,  29.,  18.,  12.,  11.,  14.,  12.,  11.,   8.,   8.,\n",
       "          6.,   4.,   8.,   6.,   6.,   3.,   4.,   8.,   0.,   4.,   0.,\n",
       "          2.,   0.,   2.,   0.,   0.,   0.,   0.,   1.,   1.,   1.,   1.,\n",
       "          1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,\n",
       "          0.]),\n",
       " array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100]),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train_match_plotter = []\n",
    "# for i in train_match_hist:\n",
    "#     train_match_plotter.append(i)\n",
    "plt.hist(train_match_hist, range(int(max(train_match_hist))+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  0.,  1.,  1.,  2.,  1.,  1.,  2.,  1.,  0.,  0.,  0.,  0.,\n",
       "         1.,  1.,  1.,  1.,  0.,  3.,  0.,  2.,  0.,  0.,  4.,  3.,  3.,\n",
       "         5.,  2.,  7.,  7.,  4.,  5.,  3.,  2.,  1.,  3.,  7.,  4.,  8.,\n",
       "         6.,  4.,  6.,  9.,  6.,  8., 10., 11., 11., 19.,  7., 12., 21.,\n",
       "        14., 19., 12., 15., 23.,  7., 12., 14., 19., 13., 19., 16., 13.,\n",
       "        19., 23., 16., 21., 22., 27., 18., 22., 24., 22., 33., 26., 20.,\n",
       "        30., 22., 24., 25., 25., 25., 30., 24., 32., 27., 34., 31., 23.,\n",
       "        20., 27., 31., 30., 33., 28., 29., 26., 24., 15., 27., 28., 23.,\n",
       "        27., 26., 21., 27., 27., 32., 21., 25., 26., 27., 18., 18., 10.,\n",
       "        26., 24., 21., 21., 16., 22., 20., 22., 21., 34., 21., 15., 16.,\n",
       "        20., 17., 17., 20., 22., 20., 14., 13., 15., 20., 14., 11., 16.,\n",
       "        11., 21., 14., 18., 16., 12., 12., 12., 12., 11., 14., 11., 13.,\n",
       "        17., 18., 10., 18., 10.,  8., 11.,  9., 16.,  7.,  7., 13.,  8.,\n",
       "         7.,  8., 14., 14., 12.,  5., 14.,  9., 12., 12., 13., 16., 13.,\n",
       "        15.,  9.,  8., 13.,  9., 10., 11.,  7., 14., 17.,  5., 11.,  9.,\n",
       "        11.,  9.,  7., 12.,  9., 12.,  8.,  7.,  7.,  4.,  6.,  9.,  7.,\n",
       "         8., 17., 12.,  7.,  8.,  5.,  6.,  5.,  9., 10., 13.,  8.,  8.,\n",
       "         4.,  5.,  5.,  6.,  8.,  6.,  5.,  9.,  5.,  6., 10.,  6.,  6.,\n",
       "         7.,  6.,  3.,  6.,  5.,  2.,  6.,  8.,  5.,  8.,  2.,  3., 11.,\n",
       "         8.,  6.,  6.,  1.,  6.,  3., 11.,  3.,  5.,  4.,  5.,  2.,  5.,\n",
       "         3.,  6.,  4.,  3.,  6.,  0.,  6.,  4.,  2.,  3.,  1.,  3.,  2.,\n",
       "         6.,  3.,  6.,  6.,  1.,  5.,  4.,  1.,  4.,  4.,  3.,  1.,  3.,\n",
       "         5.,  5.,  5.,  4.,  4.,  1.,  6.,  2.,  2.,  6.,  1.,  2.,  7.,\n",
       "         3.,  1.,  2.,  2.,  2.,  5.,  5.,  1.,  2.,  2.,  2.,  0.,  3.,\n",
       "         4.,  3.,  6.,  2.,  6.,  2.,  3.,  1.,  3.,  1.,  3.,  2.,  0.,\n",
       "         3.,  3.,  2.,  2.,  1.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  2.,  0.,  3.,\n",
       "         2.,  2.,  0.,  1.,  0.,  3.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       " array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "        247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "        260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "        273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "        286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "        299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "        325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "        338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "        351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
       "        377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
       "        390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
       "        403, 404, 405, 406, 407, 408, 409, 410]),\n",
       " <a list of 410 Patch objects>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train_nonma_plotter = []\n",
    "# for i in train_nonma_hist:\n",
    "#     train_nonma_plotter.append(i.cpu().detach().numpy())\n",
    "plt.hist(train_nonma_hist, range(int(max(train_nonma_hist))+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3506\n",
      "3506\n"
     ]
    }
   ],
   "source": [
    "# make histograms for matching and non-matching pairs\n",
    "valid_match_hist = []\n",
    "valid_nonma_hist = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for ii, sample in enumerate(dataloaders['valid']):\n",
    "        if train_on_gpu:\n",
    "            uav_img = sample['uav_image'].cuda()\n",
    "            sat_img = sample['satellite_image'].cuda()\n",
    "            label = sample['label'].cuda()\n",
    "        uav_img = uav_img.float()\n",
    "        sat_img = sat_img.float()\n",
    "        label = label.float()\n",
    "        model.eval()\n",
    "        output = model(uav_img, sat_img)\n",
    "        out = output.cpu().detach().numpy()\n",
    "        # out = out.detach().numpy()\n",
    "        for i in range(len(output)):\n",
    "            if (label[i]):\n",
    "                valid_match_hist.append(out[i])\n",
    "            else:\n",
    "                valid_nonma_hist.append(out[i])\n",
    "            \n",
    "print(len(valid_match_hist))\n",
    "print(len(valid_nonma_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,  90., 121., 114., 112.,  96., 104., 108., 118., 110., 120.,\n",
       "        103.,  88.,  95.,  96., 119., 102.,  76., 111.,  89.,  81.,  93.,\n",
       "         85.,  89.,  82.,  55.,  66.,  59.,  64.,  47.,  63.,  56.,  56.,\n",
       "         50.,  35.,  42.,  35.,  39.,  41.,  38.,  35.,  28.,  32.,  19.,\n",
       "         33.,  26.,  29.,  18.,  12.,  11.,  14.,  12.,  11.,   8.,   8.,\n",
       "          6.,   4.,   8.,   6.,   6.,   3.,   4.,   8.,   0.,   4.,   0.,\n",
       "          2.,   0.,   2.,   0.,   0.,   0.,   0.,   1.,   1.,   1.,   1.,\n",
       "          1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,\n",
       "          0.]),\n",
       " array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100]),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# valid_match_plotter = []\n",
    "# for i in match_hist:\n",
    "#     valid_match_plotter.append(i.cpu().detach().numpy())\n",
    "plt.hist(valid_match_hist, range(int(max(valid_match_hist))+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  0.,  1.,  1.,  2.,  1.,  1.,  2.,  1.,  0.,  0.,  0.,  0.,\n",
       "         1.,  1.,  1.,  1.,  0.,  3.,  0.,  2.,  0.,  0.,  4.,  3.,  3.,\n",
       "         5.,  2.,  7.,  7.,  4.,  5.,  3.,  2.,  1.,  3.,  7.,  4.,  8.,\n",
       "         6.,  4.,  6.,  9.,  6.,  8., 10., 11., 11., 19.,  7., 12., 21.,\n",
       "        14., 19., 12., 15., 23.,  7., 12., 14., 19., 13., 19., 16., 13.,\n",
       "        19., 23., 16., 21., 22., 27., 18., 22., 24., 22., 33., 26., 20.,\n",
       "        30., 22., 24., 25., 25., 25., 30., 24., 32., 27., 34., 31., 23.,\n",
       "        20., 27., 31., 30., 33., 28., 29., 26., 24., 15., 27., 28., 23.,\n",
       "        27., 26., 21., 27., 27., 32., 21., 25., 26., 27., 18., 18., 10.,\n",
       "        26., 24., 21., 21., 16., 22., 20., 22., 21., 34., 21., 15., 16.,\n",
       "        20., 17., 17., 20., 22., 20., 14., 13., 15., 20., 14., 11., 16.,\n",
       "        11., 21., 14., 18., 16., 12., 12., 12., 12., 11., 14., 11., 13.,\n",
       "        17., 18., 10., 18., 10.,  8., 11.,  9., 16.,  7.,  7., 13.,  8.,\n",
       "         7.,  8., 14., 14., 12.,  5., 14.,  9., 12., 12., 13., 16., 13.,\n",
       "        15.,  9.,  8., 13.,  9., 10., 11.,  7., 14., 17.,  5., 11.,  9.,\n",
       "        11.,  9.,  7., 12.,  9., 12.,  8.,  7.,  7.,  4.,  6.,  9.,  7.,\n",
       "         8., 17., 12.,  7.,  8.,  5.,  6.,  5.,  9., 10., 13.,  8.,  8.,\n",
       "         4.,  5.,  5.,  6.,  8.,  6.,  5.,  9.,  5.,  6., 10.,  6.,  6.,\n",
       "         7.,  6.,  3.,  6.,  5.,  2.,  6.,  8.,  5.,  8.,  2.,  3., 11.,\n",
       "         8.,  6.,  6.,  1.,  6.,  3., 11.,  3.,  5.,  4.,  5.,  2.,  5.,\n",
       "         3.,  6.,  4.,  3.,  6.,  0.,  6.,  4.,  2.,  3.,  1.,  3.,  2.,\n",
       "         6.,  3.,  6.,  6.,  1.,  5.,  4.,  1.,  4.,  4.,  3.,  1.,  3.,\n",
       "         5.,  5.,  5.,  4.,  4.,  1.,  6.,  2.,  2.,  6.,  1.,  2.,  7.,\n",
       "         3.,  1.,  2.,  2.,  2.,  5.,  5.,  1.,  2.,  2.,  2.,  0.,  3.,\n",
       "         4.,  3.,  6.,  2.,  6.,  2.,  3.,  1.,  3.,  1.,  3.,  2.,  0.,\n",
       "         3.,  3.,  2.,  2.,  1.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  2.,  0.,  3.,\n",
       "         2.,  2.,  0.,  1.,  0.,  3.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       " array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "        247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "        260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "        273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "        286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "        299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "        325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "        338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "        351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
       "        377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
       "        390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
       "        403, 404, 405, 406, 407, 408, 409, 410]),\n",
       " <a list of 410 Patch objects>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# valid_nonma_plotter = []\n",
    "# for i in valid_nonma_hist:\n",
    "#     valid_nonma_plotter.append(i.cpu().detach().numpy())\n",
    "plt.hist(valid_nonma_hist, range(int(max(valid_nonma_hist))+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(uav_img_path, sat_img_path, true_label, model):\n",
    "    uav_img = io.imread(uav_img_path)\n",
    "    sat_img = io.imread(sat_img_path)\n",
    "    sample = {'uav_image': uav_img, 'satellite_image': sat_img, 'label':true_label}\n",
    "\n",
    "    single_transform = transforms.Compose([Rescale(256),ToTensor()])\n",
    "    sample = single_transform(sample)\n",
    "\n",
    "    uav_img = (sample['uav_image']).float()\n",
    "    sat_img = (sample['satellite_image']).float()\n",
    "    if train_on_gpu:\n",
    "        uav_img = uav_img.view(1, 3, 256, 256).cuda()\n",
    "        sat_img = sat_img.view(1, 3, 256, 256).cuda()\n",
    "        # Set to evaluation\n",
    "#     TODO: if train_on_gpu is False\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        out = model(uav_img, sat_img)\n",
    "        print('Actual value ', true_label)\n",
    "        print('Distance is ', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual value  False\n",
      "Distance is  tensor([111.1536], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# choose in range 0 to 148\n",
    "test_uav_no = 185\n",
    "test_sat_no = 186\n",
    "test_uav = uav_img_dir + 'uav' + str(test_uav_no) + '.png'\n",
    "test_sat = sat_img_dir + 'sat' + str(test_sat_no) + '.png'\n",
    "true_label = match_array[test_uav_no, test_sat_no]\n",
    "make_prediction(test_uav, test_sat, true_label, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
